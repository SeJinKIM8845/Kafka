# 4장 카프카의 내부 동작 원리와 구현

## Kafka 리플리케이션 개요

리플리케이션 

- Kafka는 **데이터 내구성**과 **고가용성**을 위해 파티션 데이터를 여러 브로커에 복제.
- 각 파티션은 하나의 **리더(Leader)**와 여러 **팔로워(Follower)**로 구성.
- 리플리케이션 복제본(replica)은 리더와 팔로워로 나뉨
    - **리더(Leader)**: 읽기/쓰기 요청을 처리.
    - **팔로워(Follower)**: 리더의 데이터를 복제하고 백업 역할 수행.

## **리플리케이션의 목표**

1. **데이터 손실 방지**: 브로커 장애 시 다른 복제본이 데이터를 유지.
2. **고가용성**: 리더 장애 시 팔로워 중 하나가 새로운 리더로 승격.
3. **읽기 확장성**: 특정 설정에서 팔로워를 읽기 요청에 활용 가능.

## **리플리케이션 설정**

리플리케이션은 토픽 생성 시 설정

[kafka-topics.sh](http://kafka-topics.sh/) --create \
--topic drone_data \
--partitions 3 \
--replication-factor 3 \
--bootstrap-server kafka01:9092

## 리더와 팔로워의 역할

### **리더(Leader)**

- 각 파티션의 **리더는 유일하게 읽기/쓰기 요청을 처리**.
- 리더는 데이터를 팔로워로 복제하여 데이터 일관성을 유지.

### **팔로워(Follower)**

- 팔로워는 리더로부터 데이터를 복제(fetch).
- **ISR (In-Sync Replica)**: 리더와 동기화 상태를 유지하는 팔로워 집합.
- 팔로워가 리더와 동기화되지 못하면 ISR에서 제거.

## 리플리케이션 동작 단계

### **쓰기 요청 처리**

1. Producer는 특정 파티션의 리더에게 메시지를 보냄.
2. 리더는 메시지를 자신의 로그에 기록.
3. 리더는 메시지를 ISR의 모든 팔로워로 전송.
4. ISR 내 모든 팔로워가 메시지를 기록하면, 리더는 Producer에게 "쓰기 완료"를 응답.

### **데이터 복제 유지**

팔로워는 주기적으로 리더에게 데이터를 가져옵니다.

- **팔로워 복제 단계**:
    1. 팔로워는 `Fetch Request`를 리더에 전송.
    2. 리더는 최신 데이터를 팔로워에게 전송.
    3. 팔로워는 데이터를 자신의 로그에 기록.
    4. 리더는 팔로워의 오프셋을 ISR에 업데이트.

### **커밋과 데이터 일관성**

- **커밋(Commit)**: 리더가 메시지를 "확정"하고 Consumer에게 제공 가능 상태로 만듦.
- 메시지는 ISR 내 모든 복제본이 기록한 후 커밋됨.

## **리더 에포크(Leader Epoch)와 장애 복구**

### **리더 에포크란?**

- 리더가 변경될 때마다 **리더 에포크 번호(epoch number)**가 증가.
- Consumer와 Producer는 새로운 리더를 에포크 번호를 통해 식별.

### **장애 복구 과정**

1. 리더가 장애 발생 시, 새로운 리더를 ISR 내 팔로워에서 선출.
2. 새로운 리더는 기존 리더의 복제본에서 최신 데이터를 가져와 리더 역할 수행.

### **단계별 복구**

1. **장애 감지**:
    - ZooKeeper 또는 KRaft가 리더의 장애를 감지.
2. **리더 선출**:
    - ISR 내 가장 최신 오프셋을 가진 팔로워를 새로운 리더로 선출.
3. **에포크 번호 증가**:
    - 새로운 리더는 에포크 번호를 증가.
4. **팔로워 동기화**:
    - 다른 복제본은 새로운 리더와 동기화.

## **리플리케이션 유지 방법**

Kafka는 다음을 통해 리플리케이션 동기화를 유지:

1. **주기적 Fetch Request**: 팔로워는 리더의 새로운 데이터를 가져옴.
2. **ISR 관리**:
    - 팔로워가 일정 시간 동안 리더와 동기화되지 않으면 ISR에서 제외.
3. **데이터 일관성 확인**:
    - 리더는 팔로워의 오프셋 상태를 주기적으로 확인.

## **데이터 일관성 모델**

Kafka는 **리더-기반 강력한 일관성 모델**을 사용:

1. 모든 쓰기 작업은 리더를 통해 이루어짐.
2. 읽기 작업은 리더 또는 동기화된 팔로워에서 수행 가능.

## **Kafka 컨트롤러 (Controller)**

### **컨트롤러의 역할**

Kafka 컨트롤러는 Kafka 클러스터에서 **메타데이터 관리와 리더 선출**을 담당하는 핵심 컴포넌트.

- ZooKeeper 또는 KRaft(Kafka Raft)를 통해 클러스터 상태를 관리.
- 컨트롤러는 클러스터 내의 브로커 중 하나에 의해 수행.

### **컨트롤러의 주요 기능**

1. **리더 선출**:
    - 각 파티션의 리더를 결정.
    - 리더 장애 시 새로운 리더를 선출.
2. **ISR 관리**:
    - ISR(In-Sync Replica)을 업데이트.
    - ISR 복제본이 리더와 동기화되지 않을 경우, ISR에서 제거.
3. **파티션 재할당**:
    - 새로운 브로커가 추가되거나 기존 브로커가 제거될 때 파티션을 재할당.
4. **브로커 상태 관리**:
    - 클러스터에서 브로커가 등록되거나 장애로 인해 종료될 경우 이를 감지하고 메타데이터를 업데이트.

### **컨트롤러의 동작**

1. 컨트롤러 브로커는 ZooKeeper(KRaft)에서 컨트롤러 역할을 획득.
2. 컨트롤러는 클러스터 상태를 확인하고 리더 선출 및 ISR을 업데이트.
3. 장애가 발생하거나 브로커가 추가되면 컨트롤러가 관련 작업을 수행.

### **컨트롤러 예제**

- 클러스터: `kafka01`, `kafka02`, `kafka03`
- **컨트롤러**: `kafka01` (ZooKeeper에서 컨트롤러 역할 획득).

### **컨트롤러 작업 흐름**

1. `kafka02` 장애 발생.
2. `kafka01`(컨트롤러)이 `kafka02`가 리더로 있던 파티션의 새로운 리더를 ISR에서 선출.
3. 메타데이터를 업데이트하여 새로운 리더 정보를 다른 브로커에 전달.

## **Kafka 로그(Log)**

Kafka의 로그는 메시지를 저장하는 기본 구조로, **각 파티션마다 별도의 로그 파일**로 관리.

### **로그 구조**

Kafka 로그는 **로그 세그먼트(Log Segment)**로 나뉩.

- **세그먼트**: 로그를 일정 크기나 시간 단위로 나눈 작은 파일.
- **활성 세그먼트(Active Segment)**: 새 메시지가 추가되는 현재 세그먼트.
- **비활성 세그먼트(Inactive Segment)**: 더 이상 쓰기가 일어나지 않는 세그먼트.

### **로그 파일 구성**

- **index 파일**: 오프셋과 물리적 위치를 매핑.
- **log 파일**: 메시지 데이터를 저장.
- **timeindex 파일**: 타임스탬프와 오프셋을 매핑.

### **로그 예제**

### **환경**

- 파티션: `partition-0`
- 로그 파일 경로: `/var/lib/kafka-logs/topic-0-partition-0`

### **로그 파일**

00000000000000000000.log      # 첫 번째 로그 세그먼트
00000000000000000000.index    # 첫 번째 세그먼트의 인덱스
00000000000000000000.timeindex # 첫 번째 세그먼트의 타임스탬프 인덱스
00000000000000010000.log      # 두 번째 로그 세그먼트
00000000000000010000.index
00000000000000010000.timeindex

## **로그 세그먼트 삭제(Log Deletion)**

Kafka는 메시지 보존 정책에 따라 오래된 로그 세그먼트를 삭제하여 저장 공간을 관리.

### **로그 삭제 조건**

로그 삭제는 다음 설정에 의해 결정

1. **log.retention.bytes**:
    - 각 파티션이 사용할 수 있는 최대 크기(바이트 단위).
    - 초과 시 가장 오래된 세그먼트가 삭제.
    
    log.retention.bytes=1073741824  # 1GB
    
2. **log.retention.hours**:
    - 로그를 유지할 최대 시간(기본값: 168시간 = 7일).
    
    log.retention.hours=168
    
3. **log.segment.bytes**:
    - 각 세그먼트의 최대 크기.
    - 이 크기를 초과하면 새로운 세그먼트가 생성.
    
    log.segment.bytes=104857600  # 100MB
    

### **로그 삭제 흐름**

1. 로그 세그먼트가 설정된 보존 정책을 초과하면 삭제 후보가 됨.
2. Kafka의 백그라운드 스레드(LogCleaner)가 오래된 세그먼트를 제거.

### **로그 삭제 예제**

### **환경 설정**

- `log.retention.bytes=500000000` (500MB)
- `log.segment.bytes=100000000` (100MB)

### **동작**

1. 각 파티션에 5개의 세그먼트가 생성(각 100MB).
2. 새로운 세그먼트가 생성되면서 총 크기가 600MB로 증가.
3. 가장 오래된 세그먼트(첫 번째 세그먼트)가 삭제.

## **로그 세그먼트 컴팩션(Log Compaction)**

### **로그 컴팩션이란?**

- 로그 컴팩션은 특정 키의 **최신 값만 유지**하고, 이전 값을 삭제하는 과정.
- Kafka는 컴팩션을 통해 메시지의 키별 최신 상태를 유지.

### **로그 컴팩션의 동작**

1. 메시지 키를 기준으로 오래된 값을 제거.
2. 키가 없는 메시지(null 키)는 컴팩션 대상에서 제외.
3. 키의 값이 `null`이면 해당 키에 대한 모든 기록이 삭제.

### **로그 컴팩션 설정**

log.cleanup.policy=compact  # 로그 컴팩션 활성화.

### **로그 컴팩션과 삭제의 차이**

| **구분** | **로그 삭제(Log Deletion)** | **로그 컴팩션(Log Compaction)** |
| --- | --- | --- |
| **목적** | 오래된 메시지를 제거 | 최신 데이터만 유지 |
| **기준** | 시간 또는 크기 초과 | 키별 최신 값 유지 |
| **적용 사례** | 데이터 스트리밍 | 상태 저장 데이터 (예: 상태 업데이트) |
