# 3장 기본 개념 / 구조

- 주키퍼(ZooKeeper) - 카프카의 메타데이터 관리 및 브로커의 정상상태 점검 담당
- 카프카(Kafka) / 카프카 클러스터(Kafka cluster) - 아파치 프로젝트 애플리케이션, 여러 대의 브로커를 구성한 클러스터를 의미
- 브로커(broker) - 카프카 애플리케이션이 설치된 서버 또는 노드
- 프로듀서(producer) - 카프카로 메세지를 보내는 역할을 하는 클라이언트
- 컨슈머(consumer) - 카프카에서 메세지를 꺼내가는 역할을 하는 클라이언트
- 토픽(topic) - 메세지 피드들을 토픽으로 구분하고, 각 토픽의 이름은 카프카 내에서 고유함
- 파티션(partition) - 병렬 처리 및 고성능을 얻기 위해 하나의 토픽을 여러 개로 나눈 것
- 세그먼트(segment) - 프로듀서가 전송한 실제 메세지가 브로커의 로컬 디스크에 저장되는 파일
- 메세지(message) or 레코드(record): 프로듀서가 브로커로 전송하거나 컨슈머가 읽어가는 데이터 조각

### 리플리케이션(replication)

- 각 메세지들을 여러 개로 복제해서 카프카 클러스터 내의 브로커들에게 분산시키는 동작 → 하나의 브로커가 종료되더라도 카프카는 안정성을 유지 할 수 있음

리플리케이션 팩터 수가 커지면 안정성은 높아지지만 브로커 리소스를 많이 사용하게 됨 → 복제에 대한 오버헤드를 줄여서 최대한 브로커를 효율적으로 사용할 것 

테스트나 개발 환경 - 리플리케이션 팩터 수를 1로 설정

운영 환경(로그성 메시지로서 약간의 유실 허용) - 리플리케이션 팩터 수 2 설정

운영 환경(유실 허용하지 않음) - 리플리케이션 팩터 수를 3으로 설정

### 파티션

- 하나의 토픽이 한 번에 처리 할 수 있는 한계를 높이기 위해 토픽 하나를 여러 개로 나눠 병렬처리가 가능하게 만든 것(분산 처리 가능) 나뉜 파티션 수 만큼 컨슈머 연결 가능

파티션 수는 초기에 생성 후 늘릴 수 있지만, 한번 늘린 파티션 수는 절대로 줄일 수 없음

![image.png](image.png)

컨슈머의 LAG : ‘프로듀서가 보낸 메세지 수(카프카에 남아 있는 메세지 수) - 컨슈머가 가져간 메세지 수’

LAG 지표를 통해 컨슈머에 지연이 없는지 확인

### 세그먼트

- 프로듀서에 의해 브로커로 전송된 메세지는 토픽의 파티션에 저장 → 각 메세지들은 세그먼트라는 로그 파일의 형태로 브로커의 로컬 디스크에 저장됨

![image.png](image%201.png)

hexdump - 명령어 xxd

분산 시스템 - 네트워크상에서 연결된 컴퓨터들의 그룹 / 장애 대응, 부하가 높은 경우 시스템 확장이 용이

![image.png](image%202.png)

페이지 캐시(page cache) - 높은 처리량을 얻기 위한 기능 / 직접 디스크에 읽고 쓰는 대신 물리 메모리 중 애플리케이션이 사용하지 않는 일부 잔여 메모리를 활용 → 디스크 I/O에 대한 접근이 줄어듬

배치 전송 처리, 압축 전송 - 카프카에서 지원하는 압축 타입(gzip,snappy,lz4,zstd) 

- 높은 압축률이 필요하면(gzip,zstd), 빠른 응답 속도(lz4,snappy) 권장

토픽,파티션,오프셋 - 토픽이란 곳에 데이터를 저장 → 병렬 처리를 위해 파티션 단위로 나뉨 → 파티션 메세지가 저장되는 위치 → 오프셋(offset) 순차적으로 증가하는 숫자(64비트 정수) 형태

오프셋은 고유한 숫자로 메세지의 순서를 보장하고 컨슈머에서는 마지막까지 읽은 위치를 알 수 있음

![image.png](image%203.png)

고가용성 보장 - 리플리케이션 기능은 토픽 자체를 복제하는 것이 아니라 토픽의 파티션을 복제 원본과 리플리케이션을 구분하기 위해 리더(leader),팔로워(follower)라고 함

주키퍼의 의존성 - 지노드(znode)를 이용해 카프카의 메타 정보가 주키퍼에 기록, 지노드를 이용해 브로커 노드,토픽,컨트롤러 관리 등을 함

### 프로듀서 디자인

### 프로듀서의 주요 옵션

bootstrap.servers - 클라이언트가 카프카 클러스터에 처음 연결하기 위한 호스트의 포트 정보를 나타냄

client.dns.lookup - 하나의 호스트에 여러 IP를 매핑해 사용하는 일부 환경에서 클라이언트가 하나의 IP와 연결하지 못할 경우에 다른 IP로 시도하는 설정

- use_all_dns_ips가 기본값, DNS에 할당된 호스트의 모든 IP를 쿼리하고 저장
- resolve_canonical_bootstrap_servers_only 옵션은 커버로스(Kerberos) 환경에서 FQDN을 얻기 위한 용도

acks -

buffer.memory - 프로듀서가 카프카 서버로 데이터를 보내기 위해 잠시 대기 할 수 있는 전체 메모리 byte

compression.type - 프로듀서가 메시지 전송 시 선택할 수 있는 압축 타입(none,gzip,snappy,lz4,zstd)

enable.idempotence - 설정을 true → 중복 없는 전송, 동시에 in.flight.requests.per.connection은 5이하, retries는 0이상,acks는 all로 설정

max.in.flight.requests.per.connection - 하나의 커넥션에서 프로듀서가 최대한 ACK 없이 전송할 수 있는 요청 수, 메세지의 순서가 중요하면 → 1 → 성능 저하

retries - 일시적인 오류로 인해 전송에 실패한 데이터를 다시 보내는 횟수

batch.size - 프로듀서는 동일한 파티션으로 보내는 여러 데이터를 함께 배치로 보내려고 시도 → 성능 도움

linger.ms - 메세지를 위해 기다리는 시간을 조정

transactional.id - ‘정확히 한 번 전송’을 위해 사용하는 옵션, 동일한 TransactionalID에 한해 정확히 한 번을 보장, 옵션을 사용하기 전 enable.idempotence를 true로 설정

```bash
kafka-topics.sh --bootstrap-server<  >.foo.bar:9092 --create --topic <  > --partitions 1 --replication-factor 3
토픽 생성
```

### 프로듀서 전송 방법

- 메시지를 보내고 확인하지 않기
- 동기 전송
- 비동기 전송

### 컨슈머의 주요 옵션

bootstrap.servers - 프로듀서와 동일하게 브로커의 정보를 입력

fetch.min.bytes - 한번에 가져올 수 있는 최소 데이터 크기, 데이터가 누적될 때까지 기다림

group.id - 컨슈머가 속한 컨슈머 그룹을 식별하는 식별자

heartbeat.interval.ms - 컨슈머의 상태가 active임을 의미, session.timeout.ms와 밀접한 관계가 있음, session.timeout.ms보다 낮은 값으로 설정 1/3

max.partition.timeout.ms - 파티션당 가져올 수 있는 최대 크기를 의미

enable.auto.commit - 컨슈머가 종료된 것인지를 판단

auto.offset.reset - 백그라운드로 주기적으로 오프셋을 커밋

fetch.max.bytes - 한 번의 가져오기 요청으로 가져올 수 있는 최대 크기

group.instance.id - 컨슈머의 고유 식별자

isolation.level - 트랜잭션 컨슈머에서 사용되는 옵션으로, read_uncommitted는 기본값으로 모든 메세지를 읽고, read_committed는 트랜잭션이 완료된 메시지만 읽음

max.poll.records - 한 번의 poll() 요청으로 가져오는 최대 메시지 수

partition.assignment.strategy - 파티션 할당 전략이며, 기본값은 range

fetch.max.wait.ms - fetch.min.bytes에 의해 설정된 데이터보다 작은 경우 요청에 대한 응답을 기다리는 최대 시간
