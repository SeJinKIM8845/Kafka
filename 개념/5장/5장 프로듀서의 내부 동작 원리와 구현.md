# 5장 프로듀서의 내부 동작 원리와 구현

### **Producer의 데이터 전송 흐름**

1. **레코드 생성**:
    - 사용자가 Producer API를 호출하면 메시지(레코드)가 생성.
    - 레코드는 **키(key)**, **값(value)**, **헤더(headers)**를 포함.
    
    producer.send("topic-name", key="key1", value="value1")
    
2. **파티션 결정**:
    - 파티셔너(Partitioner)가 메시지가 어느 파티션에 기록될지 결정.
    - 파티션 결정 방식:
        - 키가 있는 경우: 키의 해시값을 사용.
        - 키가 없는 경우: 라운드 로빈 또는 스티키 파티셔닝 전략 적용.
3. **배치(Buffering)**:
    - 같은 파티션으로 가는 메시지를 배치로 묶어 전송.
    - 배치는 **배치 크기(`batch.size`)** 또는 **대기 시간(`linger.ms`)** 기준으로 생성.
4. **직렬화(Serialization)**:
    - 키와 값을 **직렬화(serializer)**하여 바이트 형태로 변환.
    - Producer 설정에서 `key.serializer`와 `value.serializer`를 사용.
5. **브로커 전송**:
    - 전송된 메시지는 Kafka 브로커의 리더 파티션에 기록.
    - 브로커는 메시지를 기록한 후 ACK(확인 응답)를 반환.

### **Producer의 주요 설정**

1. **배치 관련 설정**:
    - `batch.size`: 배치 크기 (기본값: 16KB).
    - `linger.ms`: 배치를 생성하기 위해 대기하는 최대 시간 (기본값: 0ms).
2. **재전송 관련 설정**:
    - `retries`: 전송 실패 시 재시도 횟수.
    - `retry.backoff.ms`: 재시도 전 대기 시간.
3. **압축**:
    - `compression.type`: 메시지 압축 방식 (gzip, snappy, lz4, zstd).
4. **파티션 전략**:
    - `partitioner.class`: 사용자 정의 파티셔너를 설정 가능.

## **파티셔너 (Partitioner)**

파티셔너는 메시지가 **어느 파티션에 저장될지 결정하는 컴포넌트**.

### **파티셔너의 역할**

1. **파티션 결정**:
    - 메시지의 키와 파티션 전략에 따라 적절한 파티션을 선택.
2. **데이터 분산**:
    - 메시지를 파티션에 고르게 분산하거나 특정 파티션으로 집중시킬 수 있음.

### **파티션 결정 프로세스**

1. 메시지가 `Producer.send()` 호출을 통해 전송.
2. Producer는 파티셔너를 호출하여 파티션을 결정:
    - **Key가 있을 경우**: 키의 해시값을 기반으로 파티션 결정.
    - **Key가 없을 경우**: 라운드 로빈 또는 스티키 파티셔닝 전략 적용.
3. 결정된 파티션에 메시지를 추가.

### **기본 파티셔너 (Default Partitioner)**

Kafka의 기본 파티셔너는 다음 규칙에 따라 동작:

1. **Key가 있는 경우**:
    - `hash(key) % num_partitions`를 사용해 파티션 결정.
    - 동일한 키는 항상 동일한 파티션에 저장.
2. **Key가 없는 경우**:
    - **라운드 로빈** 또는 **스티키 파티셔닝** 전략을 사용.

## **라운드 로빈 전략**

### **라운드 로빈(Round Robin)이란?**

- 메시지가 순차적으로 모든 파티션에 분배되도록 설계된 방식.
- **Key가 없는 메시지**에 사용되며, 파티션 간 균등한 부하 분산을 제공.

### **라운드 로빈의 동작 원리**

1. **초기 상태**:
    - Producer는 각 토픽의 파티션 목록을 로드.
    - 다음에 메시지를 보낼 파티션을 추적하는 인덱스를 유지.
2. **파티션 결정**:
    - 메시지가 전송되면, 현재 인덱스의 파티션에 메시지를 추가.
    - 이후 인덱스를 증가시켜 다음 메시지에 적용.
3. **순환**:
    - 마지막 파티션에 도달하면 첫 번째 파티션으로 다시 순환.

## **스티키 파티셔닝 전략**

### **스티키 파티셔닝(Sticky Partitioning)이란?**

- **Kafka 2.4.0 이상**에서 도입된 파티셔닝 전략.
- 라운드 로빈과 달리 **일정 시간 동안 동일한 파티션에 메시지를 묶어서 전송**.
- 배치의 크기(`batch.size`)가 가득 차거나 타이머(`linger.ms`)가 만료되면 다음 파티션으로 이동.

### **스티키 파티셔닝의 동작 원리**

1. 메시지가 전송되면 Producer는 특정 파티션에 배치를 생성.
2. 배치가 가득 차거나 `linger.ms`가 만료될 때까지 해당 파티션에 메시지를 계속 추가.
3. 새로운 배치가 필요하면 다음 파티션으로 이동.

### **메시지 전송의 세 가지 보장 수준**

Kafka에서 메시지 전송은 세 가지 수준으로 보장됩니다:

**At Most Once**:

- 메시지가 최대 한 번만 전송.
- 데이터 손실 가능성 존재.
- `enable.idempotence=false` 및 `acks=0` 설정 시.

**At Least Once**:

- 메시지가 적어도 한 번 전송.
- 중복 메시지가 발생할 가능성 있음.
- `enable.idempotence=false` 및 `acks=all` 설정 시.

**Exactly Once (정확히 한 번)**:

- 메시지가 정확히 한 번 전송되고, 중복이나 손실이 발생하지 않음.
- Kafka의 **Idempotent Producer**와 **Transactional API**를 통해 구현.

### **Kafka의 EOS 목표**

- **중복 없는 전송**: 동일 메시지가 두 번 처리되지 않도록 보장.
- **데이터 일관성**: 메시지가 처리되는 동안 장애가 발생해도 중단된 상태에서 복구 가능.
- **분산 시스템과 통합**: Kafka 브로커, Producer, Consumer 및 외부 스토리지 시스템에서 정확한 데이터 전달 보장.

중복 없는 전송의 구현: Kafka Idempotent Producer

Idempotent Producer의 동작 원리

### **작동 방식**

1. **Producer ID(PID)**:
    - Kafka는 Producer에게 고유한 **PID(Producer ID)**를 할당.
    - PID는 메시지를 식별하고 중복 메시지를 방지하는 데 사용.
2. **Sequence Number**:
    - Producer는 각 메시지에 **Sequence Number**를 부여.
    - 브로커는 PID와 Sequence Number를 검증하여 중복 메시지 제거.
3. **중복 방지**:
    - 동일 PID와 Sequence Number의 메시지가 다시 도착하면 브로커가 이를 무시.

정확히 한 번 전송(Exactly Once Semantics, EOS): Kafka의 트랜잭션 API

### **트랜잭션 API의 개념**

Kafka의 트랜잭션은 메시지를 **원자적으로 처리**:

1. **Producer 트랜잭션**:
    - 여러 파티션에 메시지를 전송하는 작업을 하나의 트랜잭션으로 처리.
2. **Consumer 트랜잭션**:
    - 읽고 처리한 메시지의 상태를 트랜잭션에 포함.
3. **Commit 또는 Abort**:
    - 트랜잭션이 완료되면 **Commit**.
    - 중간에 실패하면 **Abort**.

트랜잭션 API의 단계별 동작

### **단계별 동작**

1. **트랜잭션 초기화**:
    - Producer는 `transactional_id`를 사용하여 트랜잭션을 시작.
2. **메시지 전송**:
    - Producer는 여러 파티션에 메시지를 전송.
    - 메시지는 트랜잭션 로그에 기록.
3. **Commit 또는 Abort**:
    - 작업 성공 시 `commit_transaction()` 호출.
    - 작업 실패 시 `abort_transaction()` 호출.

## **정확히 한 번 전송의 내부 설계**

### **Kafka 트랜잭션 로그**

- Kafka는 각 트랜잭션 상태를 저장하기 위해 **트랜잭션 로그(Internal Topic)**를 사용.
- 트랜잭션 로그는 Producer의 상태(Commit/Abort)를 기록.

### **트랜잭션의 주요 컴포넌트**

1. **Transactional Coordinator**:
    - 각 트랜잭션을 관리.
    - 트랜잭션 상태(Commit/Abort)를 유지.
2. **Transaction Log**:
    - 트랜잭션 상태를 저장.
    - 장애 발생 시 트랜잭션 상태를 복구.

### **단계별 트랜잭션 설계**

1. **트랜잭션 시작**:
    - Producer가 `begin_transaction()` 호출.
    - Coordinator가 트랜잭션 로그에 상태 기록.
2. **메시지 전송**:
    - 메시지가 브로커에 기록되며 트랜잭션 로그에 포함.
3. **Commit/Abort**:
    - Coordinator가 트랜잭션 상태를 Commit 또는 Abort로 설정.
    - Consumer는 트랜잭션이 커밋된 메시지만 읽음.
